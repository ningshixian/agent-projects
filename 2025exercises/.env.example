# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_ORG_ID=your_organization_id_here  # Optional

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google AI Configuration
GOOGLE_API_KEY=your_google_api_key_here

# Other API Keys (add as needed)
SERPER_API_KEY=your_serper_api_key_here  # For web search
TAVILY_API_KEY=your_tavily_api_key_here  # Alternative search

# Model Configuration
DEFAULT_MODEL=gpt-4-turbo-preview
ANTHROPIC_MODEL=claude-3-sonnet-20240229
GOOGLE_MODEL=gemini-pro

# Application Settings
DEBUG=True
LOG_LEVEL=INFO
MAX_TOKENS=4096
TEMPERATURE=0.7

# Vector Store Configuration (if using)
CHROMA_PERSIST_DIR=./chroma_db
VECTOR_STORE_TYPE=chroma

# Monitoring (optional)
WANDB_API_KEY=your_wandb_api_key_here
WANDB_PROJECT=agentic-ai-tutorial

# Local Models Configuration
OLLAMA_HOST=http://localhost:11434
HF_HOME=./huggingface_cache  # Hugging Face cache directory
TORCH_HOME=./torch_cache     # PyTorch cache directory

# Local model preferences
DEFAULT_LOCAL_MODEL=llama3.2:3b
FALLBACK_TO_CLOUD=true
LOCAL_MODEL_TIMEOUT=30

# Hardware optimization
CUDA_VISIBLE_DEVICES=0  # GPU device to use
OMP_NUM_THREADS=4      # CPU threads for inference
TOKENIZERS_PARALLELISM=false  # Avoid tokenizer warnings
